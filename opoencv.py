import cv2
import numpy as np
import matplotlib.pyplot as plt

#è¿™éƒ¨åˆ†æ˜¯Chatgptç»™çš„åˆ¤æ–­æ–¹å‘çš„æ–¹æ³•ï¼ˆä¸å¯è¡Œï¼‰
def detect_arrow_direction(contour, image):

    # è®¡ç®—å‡¸åŒ…ï¼ˆç¡®ä¿ç®­å¤´å®Œæ•´ï¼‰
    hull = cv2.convexHull(contour)

    # é€¼è¿‘å¤šè¾¹å½¢ï¼Œæ‰¾å‡ºå…³é”®æ‹ç‚¹
    epsilon = 0.02 * cv2.arcLength(hull, True)
    approx = cv2.approxPolyDP(hull, epsilon, True)

    # è®¡ç®—å¤–æ¥çŸ©å½¢
    x, y, w, h = cv2.boundingRect(approx)

    # è®¡ç®—ç®­å¤´çš„å…³é”®ç‚¹
    left_most = tuple(contour[contour[:, :, 0].argmin()][0])  # æœ€å·¦ç‚¹
    right_most = tuple(contour[contour[:, :, 0].argmax()][0])  # æœ€å³ç‚¹
    top_most = tuple(contour[contour[:, :, 1].argmin()][0])  # æœ€ä¸Šç‚¹
    bottom_most = tuple(contour[contour[:, :, 1].argmax()][0])  # æœ€ä¸‹ç‚¹

    # è®¡ç®—é‡å¿ƒï¼ˆè´¨å¿ƒï¼‰
    M = cv2.moments(contour)
    if M["m00"] == 0:
        return "Unknown"
    cx = int(M["m10"] / M["m00"])
    cy = int(M["m01"] / M["m00"])

    # **å¯è§†åŒ–å…³é”®ç‚¹**
    cv2.circle(image, left_most, 5, (0, 255, 0), -1)  # ç»¿è‰²ï¼šæœ€å·¦ç‚¹
    cv2.circle(image, right_most, 5, (255, 0, 0), -1)  # è“è‰²ï¼šæœ€å³ç‚¹
    cv2.circle(image, top_most, 5, (0, 0, 255), -1)  # çº¢è‰²ï¼šæœ€ä¸Šç‚¹
    cv2.circle(image, bottom_most, 5, (255, 255, 0), -1)  # é’è‰²ï¼šæœ€ä¸‹ç‚¹
    cv2.circle(image, (cx, cy), 5, (0, 255, 255), -1)  # é»„è‰²ï¼šé‡å¿ƒ

    # **æ‰“å°è°ƒè¯•ä¿¡æ¯**
    print(f"ğŸ” å…³é”®ç‚¹ - å·¦: {left_most}, å³: {right_most}, ä¸Š: {top_most}, ä¸‹: {bottom_most}, è´¨å¿ƒ: ({cx}, {cy})")

    # **æ–¹å‘åˆ¤å®šé€»è¾‘**
    if cx < left_most[0]:  # ç®­å¤´å¤´éƒ¨åœ¨å·¦ä¾§
        return "Left"
    elif cx > right_most[0]:  # ç®­å¤´å¤´éƒ¨åœ¨å³ä¾§
        return "Right"
    elif cy < top_most[1]:  # ç®­å¤´å¤´éƒ¨åœ¨ä¸Šæ–¹
        return "Forward"

    return "Unknown"  # æ— æ³•è¯†åˆ«æ–¹å‘

# è¾¹ç¼˜æ£€æµ‹ï¼Œç°åº¦ï¼Œå™ªå£°ï¼Œè¾“å‡ºåŸå›¾å’Œç°åº¦å›¾è¿˜æœ‰åˆ¤æ–­ç»“æœï¼ˆmain codeï¼‰
def trackArrows_CV(image_path):
    img = cv2.imread(image_path)

    # preconditioning
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)  # Noise reduction
    edges = cv2.Canny(blurred, 50, 150)  # Canny
    # Edge detect(test)
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    largest_contour = max(contours, key=cv2.contourArea)
    x, y, w, h = cv2.boundingRect(largest_contour)
    roi = img[y:y + h, x:x + w] # ROI extraction

    # perspective transformationï¼ˆæ¥ä¸Šé¢æ–¹å‘æ£€æµ‹ï¼‰
    pts1 = np.float32([[x, y], [x + w, y], [x, y + h], [x + w, y + h]])  # åŸå§‹ ROI è§’ç‚¹
    pts2 = np.float32([[0, 0], [w, 0], [0, h], [w, h]])  # ç›®æ ‡å˜æ¢åçš„è§’ç‚¹
    matrix = cv2.getPerspectiveTransform(pts1, pts2)  # è®¡ç®—å˜æ¢çŸ©é˜µ
    roi_warped = cv2.warpPerspective(img, matrix, (w, h))  # é€è§†å˜æ¢
    # detect arrow_direction
    arrow_direction = detect_arrow_direction(largest_contour, img)



    # result of edge detection
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    axes[0].set_title("Original Picture")
    axes[0].axis("off")

    axes[1].imshow(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))
    axes[1].set_title("ROI Extraction")
    axes[1].axis("off")

    axes[2].imshow(cv2.cvtColor(roi_warped, cv2.COLOR_BGR2RGB))
    axes[2].set_title("Perspective Transformation")
    axes[2].axis("off")

    plt.suptitle(f"Arrow Direction: {arrow_direction}")  # è¿™é‡Œæ”¹æˆç®­å¤´æ–¹å‘
    plt.show()

    print(f"ç®­å¤´æ–¹å‘: {arrow_direction}")

image_paths = [
    "/Users/z.s.r/Desktop/assignment2/picture/right.jpg",
    "/Users/z.s.r/Desktop/assignment2/picture/forward.jpg",
    "/Users/z.s.r/Desktop/assignment2/picture/left.jpg"
]

for path in image_paths:
    trackArrows_CV(path)